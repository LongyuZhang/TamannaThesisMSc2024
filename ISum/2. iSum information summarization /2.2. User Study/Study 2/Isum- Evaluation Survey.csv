What is your current role within the organization?,How many years of experience do you have in software development industry?,Please record the start time of your analysis for this issue discussion.,"Review the provided issue report and provide your analysis on understanding of the bug, potential causes, and possible solution or temporary workaround. Try to answer within 5 minutes. ",Please record the end time of your analysis for this issue discussion.,How difficult did you find it to extract relevant information and understand the overall context of the issue without information type classification of issue discussion?,Please describe any specific challenges or difficulties (if any) you encountered while understanding or interpreting the issue report. Were there any parts that were particularly unclear or hard to interpret? Provide as much detail as possible.,Rate these factors on scale 1 to 100 (low to high) based on your perception of this task. [Mental Demand],Rate these factors on scale 1 to 100 (low to high) based on your perception of this task. [Physical Demand],Rate these factors on scale 1 to 100 (low to high) based on your perception of this task. [Temporal Demand],Rate these factors on scale 1 to 100 (low to high) based on your perception of this task. [Performance	],Rate these factors on scale 1 to 100 (low to high) based on your perception of this task. [Effort],Rate these factors on scale 1 to 100 (low to high) based on your perception of this task. [Frustration Level],Please record the start time of your analysis for this issue discussion.,"Review the provided issue report.
(1) Provide your analysis on the feature proposal's motivation and outcome. (2) Provide your observation as project manager on the above mentioned scenarios.

 Try to answer within 5 minutes. ",Please record the end time of your analysis for this issue discussion.,How effective the iSum classifications were in helping you extract relevant information and understand the overall context of the issue?,Please share your observations on whether iSum's classifications had an impact on your ability to objectively understand and analyze the software issues., [Mental Demand], [Physical Demand], [Temporal Demand], [Performance	], [Effort], [Frustration Level],Is there any additional feedback or comments you would like to provide regarding your experience with iSum classifications or this survey?
Developer,1-3 years,8:07:00 AM,"memory leak on TF2.0
everyone is reproducing it
clear_session works as a workaround.
trying a different nightly build solves the issue.
the cause is not clear ",8:12:00 AM,2,,60,0,80,45,70,80,8:20:00 AM,"for generalizing slicing and slice assignment ops, issue is opened and assigned to ebrevdo. One user voluntiary wanted to fix it.  I can see several workarounds have been suggested. ",8:25:00 AM,3,,20,0,40,50,35,30,
Developer,1-3 years,9:10:00 PM,"Cause: While running using tensorflow 1.14 or theano backends this code works fine.
After upgraded to tensorflow 2.0.0 it stops working and memory usage increasing without finish the program.  Solution: by turning my custom keras Iterator class into a generic class with a callable generator method (that yields batches) and using it to create a tf Dataset with tf.data.Dataset.flow_from_generator() .
Using tf Dataset got rid of the memory leak.",9:16:00 AM,3,the thread is too long for a survey,85,5,85,70,75,60,9:25:00 AM,"Motivation: to capture more of the functionality of numpy slicing. @ebrevdo is assigned , mhejrati wants to contribute. update: gather_nd extension to support inner slicing, lots of developers suggesting workaround, Potential issue:  get behavior from a user's example without the new syntax,  what's the optimal way of achieving this sort of indexing? Issue is closed as of 0.10 improved basic indexing and sliced assignment is available. Advanced, mixed advanced and basic, as well as boolean slicing still need implementation",9:30:00 AM,4,,20,5,30,15,25,10,
Developer,1-3 years,1:08:00 PM,"System Version: macOS 10.14.6 (18G103)
Kernel Version: Darwin 18.7.0 
Python 3.7.3
No GPU
After upgraded to tensorflow 2.0.0 it stops working and memory usage increasing without finish the program.
problem is probably due to a leak in Dataset.map because it does not leak when I use Keras Sequence generators.
fixed in 2.1.0-rc0",1:14:00 AM,3,,80,35,80,65,75,70,3:03:00 AM,The issue is posted for generalizing slicing and slice assignment ops and assigned to ebrevdo. ,3:08:00 AM,2,this is feature request. but the tool also tries to show bug related information,35,10,40,50,40,30,
Developer,less than 1 year,8:48:00 PM,"After upgraded to tensorflow 2.0.0 it stops working and memory usage increasing without finish the program. solution :
I iterate for each epoch and spawn a new process for it, where I do the training for 1 epoch only, save the model into a temporary directory, and then I just kill the process, which releases the RAM memory (GPU memory as well, but this issue was fixed in the latest TF and does not appear anymore in my setup). In the next iteration, I load the model from the directory and continue training. I can do the training this way. It is very bad design but it works.",9:54:00 PM,4,,90,30,90,65,75,70,10:00:00 PM,"the issue posted listed the outcome here: We should have a 2.5 dimensional set of ops, with dimensions (1) get vs. set, (2) slice type, and for the assignment ops (3) the update op. Currently we have slice, assign_update, assign_add, assign_sub, gather, scatter_update, scatter_add, scatter_sub. We should also have assign_slice_update, assign_slice_add, assign_slice_sub.
Both slicing and slice assignment should support strides, with no performance cost if strides aren't used.
Ideally, the slice ops should support negative indexing a la Python. Since the slice parameters are already CPU, this is implementable with near zero cost. The unfortunate bit is that since we picked the wrong format for specifying ranges (start + length instead of start : end), negative indexing might be awkward. Thus, it might be best left to a separate bug.
Support numpy-like boolean indexing.
Generalize gather and scatter_* to take an array of input index tensors, efficiently broadcast them, and do multidimensional indexing similar to numpy.
Make __getitem__ provide sugar for all of the above. Ideally we'd have something idiomatically similar at least to __setitem__, but this is problematic since the returned assignment op is important to have, __setitem__ does not return a value, and the nice range sugar is available only inside indexing / assignment calls. 
The idea is to  generalize slicing and slice assignment ops (including gather and scatter) and assigned @ebrevdo. mhejrati  is another potential contributor.  People are suggesting workaround. Finally with  improved basic indexing and sliced assignment, the issue got closed.However,  Advanced, mixed advanced and basic, as well as boolean slicing still need implementation",10:06:00 PM,3,,90,25,85,80,85,65,
Developer,4-5 years,5:04:00 PM,"There is a memory leak in TF2.0 with model.predict or/and model.fit with keras. After using tf.keras.backend.clear_session(), the memory leak is fixed as a workaround.",5:10:00 AM,4,give a simple issue. it is hard to go through all of this,95,35,95,95,95,95,5:15:00 AM,"They need to expand our slicing and assignment operations to mimic NumPy's functionality for generalize slicing and slice assignment ops. The thread has one volunteer, mhejrati. workaround for the case where your params variable is of unknown length has been posted. issue was closed  after fixing basic indexing and sliced assignmet.",5:20:00 AM,4,,60,25,60,65,55,45,
Developer,4-5 years,6:08:00 AM,memory leak on tf version 2. seems some tensors are being kept in GPU memory. there were a couple of recent fixes related to this 082415b c2fc448,6:14:00 AM,5,,100,85,100,100,100,100,6:21:00 AM,"To capture more of the functionality of numpy slicing, and add __getitem__ sugar for all of it, they should make slicing and assignment ops more general. the outcome : We should have a 2.5 dimensional set of ops, with dimensions (1) get vs. set, (2) slice type, and for the assignment ops (3) the update op. Currently we have slice, assign_update, assign_add, assign_sub, gather, scatter_update, scatter_add, scatter_sub. We should also have assign_slice_update, assign_slice_add, assign_slice_sub.
Both slicing and slice assignment should support strides, with no performance cost if strides aren't used.
Ideally, the slice ops should support negative indexing a la Python. Since the slice parameters are already CPU, this is implementable with near zero cost. The unfortunate bit is that since we picked the wrong format for specifying ranges (start + length instead of start : end), negative indexing might be awkward. Thus, it might be best left to a separate bug.
Support numpy-like boolean indexing.
Generalize gather and scatter_* to take an array of input index tensors, efficiently broadcast them, and do multidimensional indexing similar to numpy.
Make __getitem__ provide sugar for all of the above. Ideally we'd have something idiomatically similar at least to __setitem__, but this is problematic since the returned assignment op is important to have, __setitem__ does not return a value, and the nice range sugar is available only inside indexing / assignment calls.
",6:26:00 AM,3,,85,50,85,85,85,85,
Developer,1-3 years,3:03:00 PM,"Issue title: Memory leak on TF 2.0 with model.predict or/and model.fit with keras. Cause: could not find. Solution: I see several workaround, solution is unclear",3:08:00 PM,5,,95,75,95,90,100,100,3:18:00 PM,The issue was assigned to @ebrevdo. mhejrati expresses interest in contributing. The op wants to generalize slicing and slice assignment ops. The resolution involved improving basic indexing and sliced assignment. ,3:24:00 PM,4,,90,85,90,90,90,90,
Developer,less than 1 year,8:12:00 PM,"After upgraded to tensorflow 2.0.0 it stops working and memory usage increasing without finish the program.  Train for one epoch at a time by creating a new process, saving the model, terminating the process to free up memory, and then loading the model in the next iteration to continue training solves the issue",8:17:00 AM,4,,60,60,60,60,60,60,8:21:00 AM,"Generalize slicing and slice assignment ops (including gather and scatter)
We should make our slicing and assignment ops more general to capture more of the functionality of numpy slicing, and add __getitem__ sugar for all of it. Specifically,
We should have a 2.5 dimensional set of ops, with dimensions (1) get vs. set, (2) slice type, and for the assignment ops (3) the update op. Currently we have slice, assign_update, assign_add, assign_sub, gather, scatter_update, scatter_add, scatter_sub. We should also have assign_slice_update, assign_slice_add, assign_slice_sub.
Both slicing and slice assignment should support strides, with no performance cost if strides aren't used.
Ideally, the slice ops should support negative indexing a la Python. Since the slice parameters are already CPU, this is implementable with near zero cost. The unfortunate bit is that since we picked the wrong format for specifying ranges (start + length instead of start : end), negative indexing might be awkward. Thus, it might be best left to a separate bug.
Support numpy-like boolean indexing.
Generalize gather and scatter_* to take an array of input index tensors, efficiently broadcast them, and do multidimensional indexing similar to numpy.
Make __getitem__ provide sugar for all of the above. Ideally we'd have something idiomatically similar at least to __setitem__, but this is problematic since the returned assignment op is important to have, __setitem__ does not return a value, and the nice range sugar is available only inside indexing / assignment calls.
@ebrevdo is assigned
mhejrati wants to contribute. 
Another issue: optimal way of achieving iindexing
Resolution: improved basic indexing and sliced assignment",8:25:00 AM,4,The tool helps in finding the classified information,25,25,25,25,25,25,N/A
Developer,1-3 years,11:02:00 AM,The problem occurs when using model.predict or model.fit with Keras on tensorflow version 2. Using del and gc.collect() together as temporary fix.,11:08:00 AM,4,,95,95,95,95,95,95,11:15:00 AM,"We should have a 2.5 dimensional set of ops, with dimensions (1) get vs. set, (2) slice type, and for the assignment ops (3) the update op. Currently we have slice, assign_update, assign_add, assign_sub, gather, scatter_update, scatter_add, scatter_sub. We should also have assign_slice_update, assign_slice_add, assign_slice_sub.
Both slicing and slice assignment should support strides, with no performance cost if strides aren't used.
Ideally, the slice ops should support negative indexing a la Python. Since the slice parameters are already CPU, this is implementable with near zero cost. The unfortunate bit is that since we picked the wrong format for specifying ranges (start + length instead of start : end), negative indexing might be awkward. Thus, it might be best left to a separate bug.
Support numpy-like boolean indexing.
Generalize gather and scatter_* to take an array of input index tensors, efficiently broadcast them, and do multidimensional indexing similar to numpy.
Make __getitem__ provide sugar for all of the above. Ideally we'd have something idiomatically similar at least to __setitem__, but this is problematic since the returned assignment op is important to have, __setitem__ does not return a value, and the nice range sugar is available only inside indexing / assignment calls.
@ebrevdo is assigned and he did gather_nd extension to support inner slicing.the issue is closed after improving indexing",11:20:00 AM,3,,75,75,75,75,75,75,
Developer,4-5 years,8:10:00 PM,"Memory leak on TF 2.0 with model.predict or/and model.fit with keras. My workaround for the memory leak in dataset.map is not to use tf.data API - stick with Keras Sequence data generators. And a workaround for the leak in model.predict() - call model.predict_on_batch(), which does not have a leak.",8:15:00 AM,5,,95,70,95,85,95,85,8:25:00 AM,The title seems to be the motivation: Generalize slicing and slice assignment ops. The whole issue is talking about the outcome and mentioned assignee. Issue comments gave a lot of workarounds and finally closed. ,8:30:00 AM,4,,75,55,75,75,65,75,
Developer,6-10 years,7:12:00 PM,the issue is Memory leak on TF 2.0 with model.predict or/and model.fit with keras. high level apis that caused the memory leak. del together with gc.collect() works as a workaround.,7:17:00 PM,4,,85,75,90,90,90,90,7:25:00 PM,"Motivation is to capture more of the functionality of numpy slicing, and add __getitem__ sugar for all of it. potential contributor is mhejrati. issue is closed",7:31:00 PM,3,,65,70,60,70,70,70,
QA Engineer,4-5 years,1:23:00 PM,"Memory leak on TF 2.0 with model.predict or/and model.fit with keras. For me the memory leak is not fixed in tensorflow 2.1.0, Windows 10 and Python 3.7.6 (64 bits). After using tf.keras.backend.clear_session(), the memory leak is fixed as a workaround.",1:29:00 PM,5,,80,70,80,80,75,80,1:36:00 PM,The issue wants to generalize slicing. Assigned to @ebrevdo. fixed by improving basic indexing. I found one potential issues from comment: 'what's the optimal way of achieving this sort of indexing?',1:41:00 PM,4,,50,60,60,55,60,55,
Project Manager,4-5 years,5:01:00 PM,"Bug: Memory leak on TF 2.0 with model.predict or/and model.fit with keras. After upgraded to tensorflow 2.0.0 it stops working and memory usage increasing without finish the program. solution can be found on this comment: I iterate for each epoch and spawn a new process for it, where I do the training for 1 epoch only, save the model into a temporary directory, and then I just kill the process, which releases the RAM memory (GPU memory as well, but this issue was fixed in the latest TF and does not appear anymore in my setup). In the next iteration, I load the model from the directory and continue training. I can do the training this way. It is very bad design but it works.",5:07:00 PM,3,,80,75,80,80,80,80,5:15:00 PM,Generalize slicing and slice assignment ops (including gather and scatter),5:21:00 PM,3,,60,55,60,60,60,60,the tool needs to find information correctly
Developer,1-3 years,2:22:00 PM,Memory leak on TF 2.0 with model.predict or/and model.fit with keras. fixed in 2.1.0-rc0,2:29:00 PM,4,,80,75,80,75,80,75,2:35:00 PM,Generalize slicing and slice assignment ops (including gather and scatter). Assigned to ebrevdo. he started implement gather_nd but did not finish. Could not find any potential issues. Issue is finally closed stating 0.10 improved basic indexing and sliced assignment is available,2:40:00 PM,2,,80,85,85,80,85,85,
Developer,4-5 years,11:18:00 PM,"this is a  memory leak issue, happens in version 2 of tf. https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch This works well",11:24:00 AM,5,"the issue is quite complex and long, hard to follow",50,60,55,60,55,60,11:34:00 AM,The issue is motivated to capture functionality of slicing and generalization. outcome in in the issue description; a long list. @ebrevdo is assigned but mhejrati seems to be a volunteer.,11:39:00 AM,2,wrong tag make users to lose information,,,,,,,